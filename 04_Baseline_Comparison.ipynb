{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of Murdock and Okada (1970)\n",
    "We start by comparing how our prototype- and instance-based implementations of CMR account for behavior in a classic experiment where each item is presented just once per study phase. For these simulations, we used the dataset reported by @murdock1970interresponse. Each of 72 undergraduates performed 20 trials with study lists each consisting of 20 unique words visually presented at either 60 or 120 words per minute. Given a particular subject, words were unique both within and across trials, and randomly selected from the Toronto Word Pool [@friendly1982toronto], a widely-used collection of high frequency nouns, adjectives, and verbs.\n",
    "\n",
    "While the major focus of the original report by @murdock1970interresponse was to investigate inter-response times in single-trial free recall, here we focus consideration on the content of recorded recall sequences. Because it excludes within-list repetitions of studied items, this dataset presents the opportunity to compare model performance under simplified conditions. Since items' feature representations are assumed orthogonal under considered variants of CMR, retrieving a pattern of contextual associations given an item-based cue only requires abstraction over the cued item's pre-experimental and single experimental contextual associations. Interpretation of apparent differences in performance across model variants thus focus primarily on mechanisms for context-based item representation retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: code -- load dependencies and data\n",
    "\n",
    "from compmemlearn.fitting import murdock_objective_function, apply_and_concatenate\n",
    "from compmemlearn.models import Classic_CMR, Instance_CMR\n",
    "from compmemlearn.datasets import prepare_murdock1970_data, simulate_data\n",
    "from scipy.optimize import differential_evolution\n",
    "from numba.typed import List, Dict\n",
    "from numba.core import types\n",
    "from numba import njit\n",
    "from psifr import fr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "murd_trials0, murd_events0, murd_length0 = prepare_murdock1970_data('data/mo1970.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared the original prototype-based implementation of CMR against our novel instance-based implementation. First we evaluated each model variant based on their ability to predict the specific sequences of recalls exhibited by each participant. Considering all 20 trials performed by each participant in the dataset, we applied the differential evolution optimization technique to find for each model the parameter configuration that maximized the likelihood of recorded recall sequences. We obtained a unique optimal parameter configuration for each unique participant and each considered model variant. To measure the goodness-of-fit for each parameter configuration and corresponding model, [Figure @fig-MurdOkaFits] plots the log-likelihood of each participant's recall sequences given each model variant's corresponding optimized parameter configuration. The distribution of log-likelihood scores between participants for the PrototypeCMR and InstanceCMR model variants only marginally differ, suggesting little meaningful difference between variants in their effectiveness accounting for participant recall performance across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| code-summary: code -- 1) fit PrototypeCMR participant-by-participant\n",
    "\n",
    "cmr_free_parameters = (\n",
    "    'encoding_drift_rate',\n",
    "    'start_drift_rate',\n",
    "    'recall_drift_rate',\n",
    "    'shared_support',\n",
    "    'item_support',\n",
    "    'learning_rate',\n",
    "    'primacy_scale',\n",
    "    'primacy_decay',\n",
    "    'stop_probability_scale',\n",
    "    'stop_probability_growth',\n",
    "    'choice_sensitivity',\n",
    "    'delay_drift_rate'\n",
    ")\n",
    "\n",
    "lb = np.finfo(float).eps\n",
    "ub = 1-np.finfo(float).eps\n",
    "\n",
    "cmr_bounds = [\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, 100),\n",
    "    (lb, 100),\n",
    "    (lb, ub),\n",
    "    (lb, 10),\n",
    "    (lb, 10),\n",
    "    (lb, ub),\n",
    "]\n",
    "\n",
    "# cost function to be minimized\n",
    "# ours scales inversely with the probability that the data could have been \n",
    "# generated using the specified parameters and our model\n",
    "@njit(fastmath=True, nogil=True)\n",
    "def init_cmr(item_count, presentation_count, parameters):\n",
    "    return Classic_CMR(item_count, presentation_count, parameters)\n",
    "\n",
    "subject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\n",
    "cmr_results = []\n",
    "\n",
    "for subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n",
    "    print(subject, start_index)\n",
    "\n",
    "    # cost function to be minimized\n",
    "    # ours scales inversely with the probability that the data could have been \n",
    "    # generated using the specified parameters and our model\n",
    "    cost_function = murdock_objective_function(\n",
    "        List([murd_trials0[start_index:start_index+subject_trial_count]]), \n",
    "        List([murd_length0]),\n",
    "        init_cmr,\n",
    "        {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n",
    "         'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n",
    "        cmr_free_parameters)\n",
    "\n",
    "    cmr_results.append(differential_evolution(cost_function, cmr_bounds, disp=False))\n",
    "    print(cmr_results[-1].fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| code-summary: code -- 2) fit InstanceCMR participant-by-participant\n",
    "\n",
    "icmr_free_parameters = (\n",
    "    'encoding_drift_rate',\n",
    "    'start_drift_rate',\n",
    "    'recall_drift_rate',\n",
    "    'shared_support',\n",
    "    'item_support',\n",
    "    'learning_rate',\n",
    "    'primacy_scale',\n",
    "    'primacy_decay',\n",
    "    'stop_probability_scale',\n",
    "    'stop_probability_growth',\n",
    "#    'choice_sensitivity',\n",
    "    'context_sensitivity',\n",
    "#    'feature_sensitivity'\n",
    "    'delay_drift_rate',\n",
    ")\n",
    "\n",
    "icmr_bounds = [\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, ub),\n",
    "    (lb, 100),\n",
    "    (lb, 100),\n",
    "    (lb, ub),\n",
    "    (lb, 10),\n",
    "    (lb, 10),\n",
    "#    (lb, 10),\n",
    "#    (lb, 10)\n",
    "    (lb, ub),\n",
    "]\n",
    "\n",
    "# cost function to be minimized\n",
    "# ours scales inversely with the probability that the data could have been \n",
    "# generated using the specified parameters and our model\n",
    "@njit(fastmath=True, nogil=True)\n",
    "def init_icmr(item_count, presentation_count, parameters):\n",
    "    return Instance_CMR(item_count, presentation_count, parameters)\n",
    "\n",
    "subject_trial_count = 20 # Each subject gets 20 trials/lists a piece.\n",
    "icmr_results = []\n",
    "\n",
    "for subject, start_index in enumerate(range(0, len(murd_trials0), subject_trial_count)):\n",
    "    print(subject, start_index)\n",
    "\n",
    "    # cost function to be minimized\n",
    "    # ours scales inversely with the probability that the data could have been \n",
    "    # generated using the specified parameters and our model\n",
    "    cost_function = murdock_objective_function(\n",
    "    List([murd_trials0[start_index:start_index+subject_trial_count]]),  \n",
    "    List([murd_length0]),\n",
    "    init_icmr,\n",
    "    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n",
    "    icmr_free_parameters)\n",
    "\n",
    "    icmr_results.append(differential_evolution(cost_function, icmr_bounds, disp=False))\n",
    "    print(icmr_results[-1].fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: code -- 3) plot distribution of log-likelihoods across individual subjects\n",
    "plt.style.use('default')\n",
    "\n",
    "individual_fits = [result.fun for result in cmr_results] + [result.fun for result in icmr_results]\n",
    "labels = ['PrototypeCMR'] * len(cmr_results) + ['InstanceCMR'] * len(icmr_results)\n",
    "individual_df = pd.DataFrame(individual_fits, index=labels, columns=['Fit']).reset_index()\n",
    "individual_df.columns = ['Model', 'Fit']\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "g = sns.catplot(x='Model', y='Fit', data=individual_df, kind='violin', inner='stick')\n",
    "sns.swarmplot(x=\"Model\", y=\"Fit\", color=\"k\", size=3, data=individual_df, ax=g.ax)\n",
    "g.ax.set_ylabel('Individual-Level Fitted Model Log-Likelihoods');\n",
    "plt.savefig('individual_murdock1970.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "summary_table = pd.DataFrame(group.describe().rename(columns={'Fit':name}).squeeze()\n",
    "            for name, group in individual_df.groupby('Model')).T.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {#fig-murdokafits layout-nrow=2 layout-valign=\"center\"}\n",
    "\n",
    "![](individual_murdock1970.pdf)\n",
    "\n",
    "|       |   InstanceCMR |   PrototypeCMR |\n",
    "|:------|--------------:|---------------:|\n",
    "| count |        72     |         72     |\n",
    "| mean  |      297.128   |       296.249  |\n",
    "| std   |       52.7989 |        52.8859 |\n",
    "| min   |      156.753 |        150.988 |\n",
    "| 25%   |     258.206  |       260.956  |\n",
    "| 50%   |     299.741  |       299.763  |\n",
    "| 75%   |      331.797  |       331.946  |\n",
    "| max   |     387.742  |       390.806  |\n",
    "\n",
    "Distribution of log-likelihood scores of recall sequences exhibited by each subject under each considered model across list-lengths [@murdock1970interresponse]\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a follow-up, we also compared how readily each model could account for organizational summary statistics in the dataset. We found for each model variant the optimal parameter configuration maximizing the likelihood of the entire dataset rather than participant-by-participant. Using each fitted model variant, we simulated 1000 unique free recall trials and measured summary statistics from the result. [Figure @fig-MurdOkaSummary] plots for each model against the corresponding statistics collected over the dataset how recall probability varies as a function of serial position, how the probability of recalling an item first varies as a function of serial position, and how the conditional recall probabability of an item varies as a function of its serial lag from the previously recalled item. Recapitulating our comparison of log-likelihood distributions fitted over discrete participants, we found that both our prototype-based and instance-based CMR implementations account for these benchmark organizational summary statistics across the full dataset to similar extents. To build on this finding of broad model equivalence with respect to the results reported by @murdock1970interresponse, we consider the model variants under broader experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| code-summary: code -- 1) fit CMR to entire dataset rather than participant-by-participant\n",
    "\n",
    "cost_function = murdock_objective_function(\n",
    "    List([murd_trials0]),  \n",
    "    List([murd_length0]),\n",
    "    init_cmr,\n",
    "    {'sampling_rule': 0, 'mfc_familiarity_scale': 0, \n",
    "     'mcf_familiarity_scale': 0, 'drift_familiarity_scale': 0}, \n",
    "    cmr_free_parameters)\n",
    "\n",
    "cmr_result = differential_evolution(cost_function, cmr_bounds, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "print(cmr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| code-summary: code -- 2) fit Instance_CMR to entire dataset rather than participant-by-participant\n",
    "\n",
    "cost_function = murdock_objective_function(\n",
    "    List([murd_trials0]),  \n",
    "    List([murd_length0]),\n",
    "    init_icmr,\n",
    "    {'choice_sensitivity': 1, 'feature_sensitivity': 1}, \n",
    "    icmr_free_parameters)\n",
    "\n",
    "icmr_result = differential_evolution(cost_function, icmr_bounds, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "print(icmr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| code-summary: code -- 3) compose simulated spc, lag-crp, pfr from overall fitting results\n",
    "\n",
    "fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n",
    "for i in range(len(cmr_result.x)):\n",
    "    fitted_parameters[cmr_free_parameters[i]] = cmr_result.x[i]\n",
    "fitted_parameters['sampling_rule'] = 0\n",
    "fitted_parameters['mfc_familiarity_scale'] = 0\n",
    "fitted_parameters['mcf_familiarity_scale'] = 0\n",
    "fitted_parameters['drift_familiarity_scale'] = 0\n",
    "\n",
    "model = Classic_CMR(murd_length0, murd_length0, fitted_parameters)\n",
    "\n",
    "sim_df = simulate_data(model, 1000)\n",
    "true_df = murd_events0.copy()\n",
    "\n",
    "cmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\n",
    "cmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['PrototypeCMR', 'data'])\n",
    "cmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['PrototypeCMR', 'data'])\n",
    "cmr_pfr = cmr_pfr.query('output <= 1')\n",
    "\n",
    "fitted_parameters = Dict.empty(key_type=types.unicode_type, value_type=types.float64)\n",
    "for i in range(len(icmr_result.x)):\n",
    "    fitted_parameters[icmr_free_parameters[i]] = icmr_result.x[i]\n",
    "fitted_parameters['sampling_rule'] = 0\n",
    "fitted_parameters['choice_sensitivity'] = 1\n",
    "fitted_parameters['feature_sensitivity'] = 1\n",
    "\n",
    "model = Instance_CMR(murd_length0, murd_length0, fitted_parameters)\n",
    "\n",
    "sim_df = simulate_data(model, 1000)\n",
    "icmr_spc = apply_and_concatenate(fr.spc, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\n",
    "icmr_lag_crp = apply_and_concatenate(fr.lag_crp, sim_df, true_df, 'source', ['InstanceCMR', 'data'])\n",
    "icmr_pfr = apply_and_concatenate(fr.pnr, sim_df, true_df, contrast_name='source', labels=['InstanceCMR', 'data'])\n",
    "icmr_pfr = icmr_pfr.query('output <= 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: code -- 4) plot each summary statistic corresponding to each configured model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 15/2), sharey=False)\n",
    "\n",
    "# serial position curve\n",
    "sns.lineplot(ax=axes[0, 0], data=icmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\n",
    "axes[0, 0].set(xlabel='Study Position', ylabel='Recall Rate')\n",
    "axes[0, 0].set_xticks(np.arange(1, 21, 2))\n",
    "axes[0, 0].set_ylim((0, 1))\n",
    "\n",
    "sns.lineplot(ax=axes[1, 0], data=cmr_spc, x='input', y='recall', err_style='bars', hue='source', legend=False)\n",
    "axes[1, 0].set(xlabel='Study Position', ylabel='Recall Rate')\n",
    "axes[1, 0].set_xticks(np.arange(1, 21, 2))\n",
    "axes[1, 0].set_ylim((0, 1))\n",
    "\n",
    "# lag crp curve\n",
    "max_lag = 5\n",
    "filt_neg = f'{-max_lag} <= lag < 0'\n",
    "filt_pos = f'0 < lag <= {max_lag}'\n",
    "\n",
    "sns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_neg), x='lag', y='prob', \n",
    "             err_style='bars', hue='source', legend=False)\n",
    "sns.lineplot(ax=axes[0, 1], data=icmr_lag_crp.query(filt_pos), x='lag', y='prob', \n",
    "             err_style='bars', hue='source', legend=False)\n",
    "axes[0, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\n",
    "axes[0, 1].set_xticks(np.arange(-5, 6, 1))\n",
    "axes[0, 1].set_ylim((0, 1))\n",
    "\n",
    "sns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_neg), x='lag', y='prob', \n",
    "             err_style='bars', hue='source', legend=False)\n",
    "sns.lineplot(ax=axes[1, 1], data=cmr_lag_crp.query(filt_pos), x='lag', y='prob', \n",
    "             err_style='bars', hue='source', legend=False)\n",
    "axes[1, 1].set(xlabel='Item\\'s Lag In Study List From Last Recalled Item', ylabel='Conditional Recall Rate')\n",
    "axes[1, 1].set_xticks(np.arange(-5, 6, 1))\n",
    "axes[1, 1].set_ylim((0, 1))\n",
    "\n",
    "# pfr\n",
    "sns.lineplot(data=icmr_pfr, x='input', y='prob', err_style='bars', ax=axes[0, 2], hue='source')\n",
    "axes[0, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\n",
    "axes[0, 2].set_xticks(np.arange(1, 21, 2))\n",
    "axes[0, 2].set_ylim((0, 1))\n",
    "\n",
    "sns.lineplot(data=cmr_pfr, x='input', y='prob', err_style='bars', ax=axes[1, 2], hue='source')\n",
    "axes[1, 2].set(xlabel='Study Position', ylabel='Probability of First Recall')\n",
    "axes[1, 2].set_xticks(np.arange(1, 21, 2))\n",
    "axes[1, 2].set_ylim((0, 1))\n",
    "\n",
    "# set legend of axis 2 outside the plot, to the right\n",
    "axes[0, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "axes[1, 2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout(pad=3)\n",
    "plt.savefig('overall_murdock1970.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparison of summary statistics between each model against observed data [@murdock1970interresponse]](overall_murdock1970.pdf){#fig-murdokasummary}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
