## Analysis Approach

Our simulation analyses were designed to determine whether instance-based and prototype-based instantiations of CMR can similarly account for behavioral performance in the free recall task. This includes key benchmark phenomena such as the temporal contiguity and serial position effects, as well as for the overall sequence of responses generated by participants. We used a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items were recalled. For each model, we related this technique with an optimization technique called differential evolution [@storn1997differential] to search for the parameter configuration that maximize the likelihood of the considered data. Likelihoods assigned to datasets by models and their respective optimized parameters in turn support comparison of their effectiveness accounting for the recall sequences exhibited by participants in the data. Visualization of datasets compared to those of simulation outputs given these models with these parameters similarly help compare how well models realize temporal contiguity and serial position effects.

### Likelihood-based model comparison

To evaluate how effectively each model accounts for the responses in our datasets, we applied a likelihood-based model comparison technique introduced by @kragel2015neural that assesses model variants based on how accurately they can predict the specific sequence in which items are recalled. According to this method, repeated items and intrusions (responses naming items not presented in the list) are included from participants' recall sequences. Given an arbitrary parameter configuration and a sequences of recalls to predict, a model simulates encoding of each item presented in the corresponding study list in its respective order. Then, beginning with the first item the participant recalled in the trial, the probability assigned by the model to the recall event is recorded. Next, the model simulates retrieval of that item, and given its updated state is used to similarly predict the next event in the recall sequence - either retrieval of another item, or termination of recall - and so on until retrieval terminates. The probability that the model assigns to each event in the recall sequence conditional on previous trial events are thus all recorded. These recorded probabilities are then log-transformed and summed to obtain the log-likelihood of the entire sequence. Across an entire dataset containing multiple trials, sequence log-likelihoods can be summed to obtain a log-likelihood of the entire dataset given the model and its parameters. Higher log-likelihoods assigned to datasets by a model correspond to better effectiveness accounting for those datasets.

### Parameter Optimization

To find the parameter configuration for each model that maximizes its predicted likelihood of observed data, we applied the optimization technique called differential evolution [@storn1997differential] as implemented in the Python library scipy. Differential evolution maintains a population of possible parameter configurations; at each update, the algorithm mutates each population member by stochastically mixing them with other members of the population. If the new configuration of a member is an improvement over its previous configuration, then it becomes part of the updated population. Otherwise, the new parameter configuration is discarded. Through repetition of this process, gradually driving the population toward configurations that maximize the log-likelihood of the observed data assigned by the considered model. This maximal log-likelihood and its corresponding parameter configurations form the basis of comparison between models.

When exploring how effectively the model accounts for qualitative benchmark phenomena in free recall performance such as the temporal contiguity and serial position effects, we optimized parameter configurations and evaluated performance across all subjects in the considered dataset, except where otherwise noted. For direct comparison of the log-likelihoods of recall sequences, however, we search for optimal parameters and perform comparison at the subject level, considering distributions of log-likelihood values calculated between subjects when contrasting model versions.

### Summary Statistics

In each comparison, we use and visualize a set of summary statistics to characterize the the recall performance of both participants and of each considered model version. To make calculation of these summary statistics with respect to a model possible, we first had to simulate recall sequences using each model. We simulated 1000 unique trials for each unique study list in a considered dataset. For each trial, we simulated encoding of each list item into memory. Next, we simulated free recall according to model specifications outlined above, proceeding stochastically in ecah trial based on the probability distribution computed for each recall attempt until termination. Summary statistics characterizing a model were computed across all relevant simulations.

Our main analyses focus on the three consistent regularities across experiments reviewed above that have received especial emphasis in accounts of performance on the free recall task. To examine the extent to which datasets and model versions realize the serial position effect, we measured and visualized for each study (serial) position in study lists the rate at which items were retrieved across recall sequences. Relative retrieval rates for early-presented items reflect the magnitude of any primacy effect, while those for items in more terminal study positions measure the recency effect. To measure items retrieved at the initiation of recall across trials, we similarly measured and visualized for each serial position in study lists the rate at which items were retrieved *first* across each recall sequence.

We were similarly interested in the extent to which temporal contiguity where items studied at nearby serial positions tend to be recalled near one another at the retrieval phase of an experiment -- was exhibited across recall sequences in our considered datasets and models. To quantify this pattern, we followed the tradition of applying lag-based condition response probability (lag-CRP) analyses. Here, "lag" refers to the number of positions between two item presentations in a study list. Lag-CRP analyses measure the probability of making a recall transition of a particular positive or negative lag, conditional on transition to recall at that lag being possible. Under high temporal contiguity, recall transitions are largely to items with low lag from the last retrieved item and more rarely to items with high lag. Examining conditional response probabilities as a function of lag thus helps characterize the temporal organization of recall across trials.
